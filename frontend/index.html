<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Real-time Speech Recognition</title>
  <script src='https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js'></script>
  <style>
    body {
      font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
      max-width: 800px;
      margin: 0 auto;
      padding: 20px;
      background-color: #f5f5f5;
    }
    
    h1 {
      text-align: center;
      color: #333;
    }
    
    .controls {
      display: flex;
      justify-content: center;
      gap: 10px;
      margin: 20px 0;
    }
    
    button {
      padding: 10px 20px;
      border: none;
      border-radius: 4px;
      cursor: pointer;
      font-size: 16px;
      font-weight: bold;
      transition: all 0.3s ease;
    }
    
    #startButton {
      background-color: #4CAF50;
      color: white;
    }
    
    #startButton:hover {
      background-color: #45a049;
    }
    
    #stopButton {
      background-color: #f44336;
      color: white;
    }
    
    #stopButton:hover {
      background-color: #d32f2f;
    }
    
    .status-container {
      display: flex;
      justify-content: space-between;
      align-items: center;
      margin-bottom: 20px;
      padding: 10px;
      background-color: #e0e0e0;
      border-radius: 4px;
    }
    
    .indicator {
      display: inline-block;
      width: 12px;
      height: 12px;
      border-radius: 50%;
      margin-right: 5px;
    }
    
    .connected {
      background-color: #4CAF50;
    }
    
    .disconnected {
      background-color: #f44336;
    }
    
    .transcription-container {
      background-color: white;
      border-radius: 8px;
      padding: 20px;
      box-shadow: 0 2px 5px rgba(0, 0, 0, 0.1);
      min-height: 300px;
      max-height: 500px;
      overflow-y: auto;
    }
    
    .transcription {
      margin-bottom: 15px;
      padding-bottom: 15px;
      border-bottom: 1px solid #eee;
    }
    
    .transcription:last-child {
      border-bottom: none;
    }
    
    .speaking-indicator {
      text-align: center;
      margin-top: 20px;
      font-style: italic;
      color: #666;
    }
    
    .pulse {
      animation: pulse 1.5s infinite;
    }
    
    @keyframes pulse {
      0% { opacity: 0.5; }
      50% { opacity: 1; }
      100% { opacity: 0.5; }
    }
  </style>
</head>
<body>
  <h1>Real-time Speech Recognition</h1>
  
  <div class="status-container">
    <div>
      <span class="indicator disconnected" id="statusIndicator"></span>
      WebSocket: <span id="webSocketStatus">Not Connected</span>
    </div>
    <div id="audioStatus">Microphone: Inactive</div>
  </div>
  
  <div class="controls">
    <button id="startButton" onclick="startRecording()">Start Recording</button>
    <button id="stopButton" onclick="stopRecording()" disabled>Stop Recording</button>
  </div>
  
  <div id="speakingIndicator" class="speaking-indicator" style="display: none;">
    <span class="pulse">Listening...</span>
  </div>
  
  <div class="transcription-container" id="transcriptionContainer">
    <p class="transcription">Transcriptions will appear here when you start speaking...</p>
  </div>

  <script>
    // WebSocket configuration
    const websocket_uri = 'ws://localhost:5000';
    let bufferSize = 512;
    let AudioContext, context, processor, input, globalStream, websocket;
    let isRecording = false;
    
    // Initialize WebSocket
    initWebSocket();
    
    function downsampleBuffer(buffer, sampleRate, outSampleRate) {
      if (outSampleRate == sampleRate) {
        return buffer;
      }
      if (outSampleRate > sampleRate) {
        throw 'downsampling rate should be smaller than original sample rate';
      }
      
      const sampleRateRatio = sampleRate / outSampleRate;
      const newLength = Math.round(buffer.length / sampleRateRatio);
      const result = new Int16Array(newLength);
      let offsetResult = 0;
      let offsetBuffer = 0;
      
      while (offsetResult < result.length) {
        const nextOffsetBuffer = Math.round((offsetResult + 1) * sampleRateRatio);
        let accum = 0, count = 0;
        
        for (let i = offsetBuffer; i < nextOffsetBuffer && i < buffer.length; i++) {
          accum += buffer[i];
          count++;
        }
    
        result[offsetResult] = Math.min(1, accum / count) * 0x7fff;
        offsetResult++;
        offsetBuffer = nextOffsetBuffer;
      }
      
      return result.buffer;
    }
    
    function startRecording() {
      if (isRecording) return;
      
      // Update UI
      document.getElementById('startButton').disabled = true;
      document.getElementById('stopButton').disabled = false;
      document.getElementById('audioStatus').textContent = 'Microphone: Active';
      document.getElementById('speakingIndicator').style.display = 'block';
      
      isRecording = true;
      
      AudioContext = window.AudioContext || window.webkitAudioContext;
      context = new AudioContext({
        latencyHint: 'interactive',
      });
      
      processor = context.createScriptProcessor(bufferSize, 1, 1);
      processor.connect(context.destination);
      context.resume();
      
      const handleSuccess = function(stream) {
        globalStream = stream;
        input = context.createMediaStreamSource(stream);
        input.connect(processor);
        
        processor.onaudioprocess = function(e) {
          if (!isRecording) return;
          
          const left = e.inputBuffer.getChannelData(0);
          const left16 = downsampleBuffer(left, context.sampleRate, 16000);
          
          if (websocket && websocket.readyState === WebSocket.OPEN) {
            websocket.send(left16);
          }
        };
      };
      
      navigator.mediaDevices.getUserMedia({ audio: true, video: false })
        .then(handleSuccess)
        .catch(function(err) {
          console.error('Error accessing microphone:', err);
          isRecording = false;
          document.getElementById('startButton').disabled = false;
          document.getElementById('stopButton').disabled = true;
          document.getElementById('audioStatus').textContent = 'Microphone: Error - ' + err.message;
        });
    }
    
    function stopRecording() {
      if (!isRecording) return;
      
      isRecording = false;
      
      // Update UI
      document.getElementById('startButton').disabled = false;
      document.getElementById('stopButton').disabled = true;
      document.getElementById('audioStatus').textContent = 'Microphone: Inactive';
      document.getElementById('speakingIndicator').style.display = 'none';
      
      if (globalStream) {
        const tracks = globalStream.getTracks();
        tracks.forEach(track => track.stop());
      }
      
      if (input && processor) {
        input.disconnect(processor);
        processor.disconnect(context.destination);
      }
      
      if (context) {
        context.close().then(function() {
          input = null;
          processor = null;
          context = null;
          AudioContext = null;
        });
      }
    }
    
    function initWebSocket() {
      // Close any existing connection
      if (websocket) {
        websocket.close();
      }
      
      // Create new WebSocket
      websocket = new WebSocket(websocket_uri);
      
      // WebSocket event handlers
      websocket.onopen = function() {
        console.log("Connected to ASR server");
        updateConnectionStatus(true);
      };
      
      websocket.onclose = function(e) {
        console.log("Connection closed (" + e.code + ")");
        updateConnectionStatus(false);
        
        // Try to reconnect after 3 seconds
        setTimeout(initWebSocket, 3000);
      };
      
      websocket.onerror = function(e) {
        console.error("WebSocket error:", e);
        updateConnectionStatus(false);
      };
      
      websocket.onmessage = function(e) {
        try {
          const result = JSON.parse(e.data);
          
          if (result && result.text) {
            addTranscription(result.text);
          }
        } catch (error) {
          console.error('Error processing message:', error);
        }
      };
    }
    
    function updateConnectionStatus(connected) {
      const indicator = document.getElementById('statusIndicator');
      const status = document.getElementById('webSocketStatus');
      
      if (connected) {
        indicator.classList.remove('disconnected');
        indicator.classList.add('connected');
        status.textContent = 'Connected';
      } else {
        indicator.classList.remove('connected');
        indicator.classList.add('disconnected');
        status.textContent = 'Not Connected';
        
        // Disable recording if connection is lost
        if (isRecording) {
          stopRecording();
        }
      }
    }
    
    function addTranscription(text) {
      const container = document.getElementById('transcriptionContainer');
      
      // Create new transcription element
      const transcription = document.createElement('p');
      transcription.className = 'transcription';
      transcription.textContent = text;
      
      // Add to container
      container.appendChild(transcription);
      
      // Scroll to bottom
      container.scrollTop = container.scrollHeight;
      
      // Limit number of transcriptions (keep last 10)
      const transcriptions = container.getElementsByClassName('transcription');
      if (transcriptions.length > 10) {
        container.removeChild(transcriptions[0]);
      }
    }
    
    // Handle page unload to properly clean up
    window.addEventListener('beforeunload', function() {
      if (isRecording) {
        stopRecording();
      }
      
      if (websocket) {
        websocket.close();
      }
    });
  </script>
</body>
</html>